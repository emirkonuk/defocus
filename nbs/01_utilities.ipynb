{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "from skimage.measure import compare_ssim as SSIM #TODO: deprecated, fix that\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# https://stackoverflow.com/a/62078664 \n",
    "class Bunch(object):\n",
    "    def __init__(self, adict):\n",
    "        \"\"\"Create a namespace object from a dict, recursively\"\"\"\n",
    "        self.__dict__.update({k: self.__elt(v) for k, v in adict.items()})\n",
    "\n",
    "    def __elt(self, elt):\n",
    "        \"\"\"Recurse into elt to create leaf namepace objects\"\"\"\n",
    "        if type(elt) is dict:\n",
    "            return type(self)(elt)\n",
    "        if type(elt) in (list, tuple):\n",
    "            return [self.__elt(i) for i in elt]\n",
    "        return elt\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"Return repr(self).\"\"\"\n",
    "        return \"%s(%s)\" % (type(self).__name__, repr(self.__dict__))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.__dict__ == other.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sanity_check(args):\n",
    "    multiscale_architectures = ['MSResNet']\n",
    "    if args.model.generator.architecture in multiscale_architectures:\n",
    "        if args.model.loss.adversarial_loss.name:\n",
    "            assert args.model.loss.adversarial_loss.multiscale\n",
    "        if args.model.loss.content_loss.name:\n",
    "            assert args.model.loss.content_loss.multiscale\n",
    "        if args.model.loss.perceptual_loss.name:\n",
    "            assert args.model.loss.perceptual_loss.multiscale\n",
    "        assert args.input.pyramid_levels > 1\n",
    "    else:\n",
    "        if args.model.loss.adversarial_loss.name:\n",
    "            assert args.model.loss.adversarial_loss.multiscale is None\n",
    "        if args.model.loss.content_loss.name:\n",
    "            assert args.model.loss.content_loss.multiscale is None\n",
    "        if args.model.loss.perceptual_loss.name:\n",
    "            assert args.model.loss.perceptual_loss.multiscale is None\n",
    "        assert args.input.pyramid_levels == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# TODO: current version expects <input_image_path target_image_path> lines in the image_pair_list\n",
    "# but it shouldn't have to, the reader should be able to deal with lines having only <target_image_path>\n",
    "def get_GOPRO_lists(root_folder, image_pair_list):\n",
    "    \"\"\"Reads input image lists for the GOPRO dataset.\n",
    "    \n",
    "    This is based on my current folder structure in hekate so\n",
    "    write your own function. the output should consist of a list\n",
    "    with elements containing the FULL path (i.e. from the root).\n",
    "    \"\"\"\n",
    "    input_list = []\n",
    "    target_list = []\n",
    "    with open(image_pair_list, 'r') as f:\n",
    "        for line in f:\n",
    "            input_filename = line.split(' ')[0].strip('\\n').strip('\\t')\n",
    "            target_filename = line.split(' ')[1].strip('\\n').strip('\\t')\n",
    "            input_filepath = os.path.join(root_folder, input_filename)\n",
    "            target_filepath = os.path.join(root_folder, target_filename)\n",
    "            input_list.append(input_filepath)\n",
    "            target_list.append(target_filepath)\n",
    "    return input_list, target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# TODO: ugly and opaque, rewrite these\n",
    "def tensor2im(image_tensor, imtype=np.uint8):\n",
    "    image_list = []\n",
    "    for image in image_tensor:\n",
    "        image_numpy = image.cpu().float().numpy()\n",
    "        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
    "        image_list.append(image_numpy)\n",
    "    return np.asarray(image_list).astype(imtype)\n",
    "\n",
    "# TODO: rewrite this, wtf are those variable names!\n",
    "def get_metrics(input_, output, target) -> (float, float, np.ndarray):\n",
    "    if isinstance(target, list):\n",
    "        input_ = input_[-1]\n",
    "        output = output[-1]\n",
    "        target = target[-1]\n",
    "    fake = tensor2im(output.data)\n",
    "    real = tensor2im(target.data)\n",
    "    psnrs = []\n",
    "    ssims = []\n",
    "    for fake_, real_ in zip(fake, real):\n",
    "        psnr = PSNR(fake_, real_)\n",
    "        ssim = SSIM(fake_, real_, multichannel=True)\n",
    "        psnrs.append(psnr)\n",
    "        ssims.append(ssim)\n",
    "    psnr = np.mean(psnrs)\n",
    "    ssim = np.mean(ssims)\n",
    "\n",
    "    return psnr, ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# TODO: together with the get_metrics(), these need to be rewritten\n",
    "# TODO: (maybe) put this in some metrics.py\n",
    "# actually, rewrite in pytorch so that we can autograd if we want\n",
    "def PSNR(img1, img2):\n",
    "    mse = np.mean((img1 / 255. - img2 / 255.) ** 2)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 1\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_utilities.ipynb.\n",
      "Converted 02_architecture_common.ipynb.\n",
      "Converted 03_architecture_MSResNet.ipynb.\n",
      "Converted 04_architecture_DeblurGANv2.ipynb.\n",
      "Converted 05_blurring.ipynb.\n",
      "Converted 06_dataset.ipynb.\n",
      "Converted 07_losses.ipynb.\n",
      "Converted 08_callbacks.ipynb.\n",
      "Converted 09_model.ipynb.\n",
      "Converted fuckit.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
