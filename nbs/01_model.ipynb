{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_model.ipynb.\n",
      "Converted 02_generators.ipynb.\n",
      "Converted 03_discriminators.ipynb.\n",
      "Converted 99_diffaugment.ipynb.\n",
      "Converted Untitled.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Here be the code for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import defocus.networks.generators as generators\n",
    "import defocus.networks.discriminators as discriminators\n",
    "from torch.optim import Adam\n",
    "from adamp import AdamP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.G = None\n",
    "        self.D = None\n",
    "        self.P = None\n",
    "        self.G_opt = None\n",
    "        self.D_opt = None\n",
    "        \n",
    "    def set_generator(self, G):\n",
    "        # if G is a string, find that model in the generators.py and create it\n",
    "        if isinstance(G, str):\n",
    "            self.G = getattr(generators, G)()\n",
    "        # if not, G is a a network so set it\n",
    "        else:\n",
    "            self.G = G\n",
    "    \n",
    "    def set_discriminator(self, D):\n",
    "        # if D is a string, find that model in the discriminators.py and create it\n",
    "        if isinstance(D, str):\n",
    "            self.D = getattr(discriminators, D)()\n",
    "        # if not, D is a a network so set it\n",
    "        else:\n",
    "            self.D = D\n",
    "            \n",
    "    def set_perceptual(self, after_activation=False):\n",
    "        # this is from DeblurGANv2\n",
    "        # TODO: ESRGAN's perceptual loss version\n",
    "        conv_3_3_layer = 14\n",
    "        cnn = torchvision.models.vgg19(pretrained=True).features\n",
    "        perceptual = nn.Sequential()\n",
    "        perceptual = perceptual.eval()\n",
    "        for i, layer in enumerate(list(cnn)):\n",
    "            perceptual.add_module(str(i), layer)\n",
    "            if i == conv_3_3_layer:\n",
    "                break\n",
    "        self.P = perceptual\n",
    "        \n",
    "    def set_optimizers(self, optimizer='AdamP', lr=1e-4, betas=(0.9, 0.999), weight_decay=0, nesterov=False):\n",
    "        # note that lucidrains uses betas=(0.5, 0.9) for stylegan\n",
    "        # https://github.com/lucidrains/stylegan2-pytorch/blob/master/stylegan2_pytorch/stylegan2_pytorch.py#L565\n",
    "        \n",
    "        if optimizer=='Adam':\n",
    "            self.G_opt = Adam(self.G.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "            self.D_opt = Adam(self.D.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "        elif optimizer=='AdamP':\n",
    "            self.G_opt = AdamP(self.G.parameters(), lr=lr, betas=betas, weight_decay=weight_decay, nesterov=nesterov)\n",
    "            self.D_opt = AdamP(self.D.parameters(), lr=lr, betas=betas, weight_decay=weight_decay, nesterov=nesterov)\n",
    "        else:\n",
    "            #TODO: other optimizers, maybe from the torch_optimizers package\n",
    "            raise NotImplementedError('nope')\n",
    "                \n",
    "    def parallelize(self, device_ids, output_device):\n",
    "        self.G = nn.parallel.DistributedDataParallel(self.G, device_ids=device_ids, output_device=output_device)\n",
    "        if self.D is not None:\n",
    "            self.D = nn.parallel.DistributedDataParallel(self.D, device_ids=device_ids, output_device=output_device)\n",
    "        if self.P is not None:\n",
    "            self.P = nn.parallel.DistributedDataParallel(self.P, device_ids=device_ids, output_device=output_device)\n",
    "            \n",
    "    def save(self, model_path):\n",
    "        torch.save({'G':self.G.state_dict(),\n",
    "                    'D':self.D.state_dict(),\n",
    "                    'optimizer_G': self.G_opt.state_dict(),\n",
    "                    'optimizer_D': self.D_opt.state_dict()}, \n",
    "                   model_path)\n",
    "        \n",
    "    def load(self, model_path, isStrict=False):\n",
    "        checkpoint = torch.load(model_path)\n",
    "        self.G.load_state_dict(checkpoint['G'], strict=isStrict)\n",
    "        self.D.load_state_dict(checkpoint['D'], strict=isStrict)\n",
    "        self.G_opt.load_state_dict(checkpoint['optimizer_G'], strict=isStrict)\n",
    "        self.D_opt.load_state_dict(checkpoint['optimizer_D'], strict=isStrict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:defocus] *",
   "language": "python",
   "name": "conda-env-defocus-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
