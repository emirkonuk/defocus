{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.DeblurGANv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from skimage.transform import pyramid_gaussian\n",
    "from defocus.data.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "'''\n",
    "Here is a choice: do I switch to albumentations like Kupyn or \n",
    "keep Seungjun's basic augmentations?\n",
    "Also maybe kornia?\n",
    "'''\n",
    "class Dataset(data.Dataset):\n",
    "    # Seungjun's defaults for augmentations\n",
    "    # https://github.com/SeungjunNah/DeepDeblur-PyTorch/blob/master/src/data/common.py\n",
    "    \n",
    "    # note that this dataset's only difference is that it does not output a pyramid but\n",
    "    # single images.\n",
    "    def __init__(self, root_folder, image_pair_list,\n",
    "                 mode='train', \n",
    "                 augmentations={'hflip':0.5, \n",
    "                                'vflip':0.0, \n",
    "                                'rot90':0.5, \n",
    "                                'channel_shuffle':True, \n",
    "                                'saturation':True},\n",
    "                 crop_size=256,\n",
    "                 pyramid_scales=3,\n",
    "                 ):\n",
    "        super(Dataset, self).__init__()\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.augmentations = augmentations\n",
    "        self.crop_size = 256\n",
    "        self.pyramid_scales = pyramid_scales\n",
    "        input_list = []\n",
    "        target_list = []\n",
    "        with open(image_pair_list, 'r') as f:\n",
    "            for line in f:\n",
    "                input_filename = line.split(' ')[0].strip('\\n').strip('\\t')\n",
    "                target_filename = line.split(' ')[1].strip('\\n').strip('\\t')\n",
    "                input_filepath = os.path.join(root_folder, input_filename)\n",
    "                target_filepath = os.path.join(root_folder, target_filename)\n",
    "                input_list.append(input_filepath)\n",
    "                target_list.append(target_filepath)\n",
    "        self.input_list = input_list\n",
    "        self.target_list = target_list\n",
    "        assert len(self.input_list) == len(self.target_list)\n",
    "        self.length = len(self.input_list)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # remember that opencv has BGR order so read and convert\n",
    "        input_ = cv2.imread(self.input_list[idx])[:,:,::-1]\n",
    "        target = cv2.imread(self.target_list[idx])[:,:,::-1]\n",
    "        \n",
    "        # if testing, do nothing\n",
    "        if self.mode=='test' or self.mode=='validation':\n",
    "            pass\n",
    "        else:\n",
    "            H, W, C = input_.shape\n",
    "            patch_y = random.randrange(0, H-self.crop_size+1)\n",
    "            patch_x = random.randrange(0, W-self.crop_size+1)\n",
    "            input_ = crop(input_, patch_x, patch_y)\n",
    "            target = crop(target, patch_x, patch_y)\n",
    "        \n",
    "            # write all augmentations explicitly. why not?\n",
    "            if random.random() < self.augmentations['hflip']:\n",
    "                input_ = hflip(input_)\n",
    "                target = hflip(target)\n",
    "            if random.random() < self.augmentations['vflip']:\n",
    "                input_ = vflip(input_)\n",
    "                target = vflip(target)\n",
    "            if random.random() < self.augmentations['rot90']:\n",
    "                # clockwise/counter-clockwise\n",
    "                if random.random() < 0.5:\n",
    "                    input_ = vflip(input_)\n",
    "                    target = vflip(target)\n",
    "                input_ = rot90(input_)\n",
    "                target = rot90(target)\n",
    "            if self.augmentations['channel_shuffle']:\n",
    "                # note that this is actually a lower probability\n",
    "                # e.g. shuffled order may just be [0,1,2] again\n",
    "                rgb_order = [0,1,2]\n",
    "                random.shuffle(rgb_order)\n",
    "                input_ = channel_shuffle(input_, rgb_order)\n",
    "                target = channel_shuffle(target, rgb_order)            \n",
    "            if self.augmentations['saturation']:\n",
    "                # Seungjun's defaults\n",
    "                modifier = random.uniform(0.5, 1.5)\n",
    "                input_ = saturation(input_, modifier)\n",
    "                target = saturation(target, modifier)\n",
    "            # noise only for the input\n",
    "            # remember the GAN diffaug thing, may help if noise addition is non-leaky?\n",
    "            input_ = add_gaussian_noise(input_)\n",
    "            \n",
    "        input_ = torch.from_numpy(np.ascontiguousarray(input_.astype(np.float32).transpose(2, 0, 1)))\n",
    "        target = torch.from_numpy(np.ascontiguousarray(target.astype(np.float32).transpose(2, 0, 1)))\n",
    "        \n",
    "        return input_, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_model.ipynb.\n",
      "Converted 02_architecture_common.ipynb.\n",
      "Converted 03_architecture_MSResNet.ipynb.\n",
      "Converted 04_dataset_common.ipynb.\n",
      "Converted 05_dataset_MSResNet.ipynb.\n",
      "Converted 06_trainer_MSResNet.ipynb.\n",
      "Converted 07_metrics.ipynb.\n",
      "Converted 08_architecture_DeblurGANv2.ipynb.\n",
      "Converted 09_dataset_DeblurGANv2.ipynb.\n",
      "Converted 99_diffaugment.ipynb.\n",
      "Converted Tutorial_without_lightning.ipynb.\n",
      "Converted model_without_lightning.ipynb.\n",
      "Converted trials.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
