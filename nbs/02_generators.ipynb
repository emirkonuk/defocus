{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp networks.generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.nn as nn\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_feats, kernel_size):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(n_feats, n_feats, kernel_size, padding=(kernel_size // 2))\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(n_feats, n_feats, kernel_size, padding=(kernel_size // 2))\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        residual = self.conv1(input_)\n",
    "        residual = self.activation(residual)\n",
    "        residual = self.conv2(residual)\n",
    "        output = input_ + residual\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n_feats=64, kernel_size=5, n_resblocks=19):\n",
    "        super(ResNet, self).__init__()        \n",
    "        \n",
    "        self.input_layer = nn.Conv2d(in_channels, n_feats, kernel_size, padding=(kernel_size // 2))\n",
    "        self.blocks = nn.ModuleList([])\n",
    "        for _ in range(n_resblocks):\n",
    "            self.blocks.append(ResBlock(n_feats, kernel_size))\n",
    "        self.output_layer = nn.Conv2d(n_feats, out_channels, kernel_size, padding=(kernel_size // 2))\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        x = self.input_layer(input_)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        output = self.output_layer(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class UpConv2D(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, kernel_size=5, ratio=2):\n",
    "        super(UpConv2D, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels*(ratio**2), kernel_size, padding=(kernel_size // 2))\n",
    "        self.upscale = nn.PixelShuffle(ratio)\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        x = self.conv(input_)\n",
    "        output = self.upscale(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MSResNetGenerator(nn.Module):\n",
    "    def __init__(self, n_scales = 3, n_feats=64, kernel_size=5, n_resblocks=19):\n",
    "        super(MSResNetGenerator, self).__init__()\n",
    "        \n",
    "        # Seungjun does not scale the images down to [-1,1] but rather uses [-127.5, 127.5]\n",
    "        # this self.mean variable will be used for that. wonder why he calls it the \"mean\"?\n",
    "        self.mean = 255.0 / 2\n",
    "        self.n_scales = n_scales \n",
    "        \n",
    "        coarsest_level = ResNet(in_channels=3, \n",
    "                                out_channels=3,\n",
    "                                n_feats=n_feats,\n",
    "                                kernel_size=kernel_size,\n",
    "                                n_resblocks=n_resblocks)\n",
    "        finer_levels = [ResNet(in_channels=6,\n",
    "                               out_channels=3, \n",
    "                               n_feats=n_feats, \n",
    "                               kernel_size=kernel_size, \n",
    "                               n_resblocks=n_resblocks) for _ in range(n_scales-1)]\n",
    "               \n",
    "        self.scale_networks = nn.ModuleList([]) \n",
    "        self.scale_networks.append(coarsest_level)\n",
    "        self.scale_networks.extend(finer_levels)    \n",
    "        \n",
    "        # note that the original implementation always uses 5x5 kernels (default) for upsampling\n",
    "        self.upconv_blocks = nn.ModuleList([UpConv2D() for _ in range(n_scales-1)])\n",
    "        \n",
    "    def forward(self, input_pyramid):\n",
    "        \n",
    "        output_pyramid = [None]*self.n_scales\n",
    "        for scale in range(self.n_scales): \n",
    "            if scale == 0:\n",
    "                input_ = input_pyramid[scale] - self.mean\n",
    "            else:\n",
    "                upconvolved_from_previous = self.upconv_blocks[scale-1](output_pyramid[scale-1])\n",
    "                input_ = torch.cat((input_pyramid[scale] - self.mean, upconvolved_from_previous) ,1)\n",
    "                \n",
    "            output_pyramid[scale] = self.scale_networks[scale](input_)\n",
    "        \n",
    "        return output_pyramid       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import pyramid_gaussian\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.random.rand(32,32,3)\n",
    "img = img.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyramid = pyramid_gaussian(img, 2, multichannel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyramid = map(np.ascontiguousarray, pyramid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose = partial(np.transpose, axes=(2,0,1))\n",
    "pyramid = map(transpose, pyramid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyramid = map(torch.from_numpy, pyramid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyramid = list(map(partial(torch.unsqueeze, dim=0), pyramid))\n",
    "pyramid = pyramid[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MSResNetGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(pyramid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_base_model.ipynb.\n",
      "Converted 02_generators.ipynb.\n",
      "Converted 03_discriminators.ipynb.\n",
      "Converted 99_diffaugment.ipynb.\n",
      "Converted Untitled.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:defocus] *",
   "language": "python",
   "name": "conda-env-defocus-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
