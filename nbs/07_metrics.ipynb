{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def _expand(img):\n",
    "    if img.ndim < 4:\n",
    "        img = img.expand([1] * (4-img.ndim) + list(img.shape))\n",
    "\n",
    "    return img\n",
    "\n",
    "class PSNR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PSNR, self).__init__()\n",
    "\n",
    "    def forward(self, im1, im2, data_range=None):\n",
    "        # tensor input, constant output\n",
    "\n",
    "        if data_range is None:\n",
    "            data_range = 255 if im1.max() > 1 else 1\n",
    "\n",
    "        se = (im1-im2)**2\n",
    "        se = _expand(se)\n",
    "\n",
    "        mse = se.mean(dim=list(range(1, se.ndim)))\n",
    "        psnr = 10 * (data_range**2/mse).log10().mean()\n",
    "\n",
    "        return psnr\n",
    "\n",
    "class SSIM(nn.Module):\n",
    "    def __init__(self, device_type='cpu', dtype=torch.float32):\n",
    "        super(SSIM, self).__init__()\n",
    "\n",
    "        self.device_type = device_type\n",
    "\n",
    "        def _get_ssim_weight():\n",
    "            truncate = 3.5\n",
    "            sigma = 1.5\n",
    "            r = int(truncate * sigma + 0.5)  # radius as in ndimage\n",
    "            win_size = 2 * r + 1\n",
    "            nch = 3\n",
    "\n",
    "            weight = torch.Tensor([-(x - win_size//2)**2/float(2*sigma**2) for x in range(win_size)]).exp().unsqueeze(1)\n",
    "            weight = weight.mm(weight.t())\n",
    "            weight /= weight.sum()\n",
    "            weight = weight.repeat(nch, 1, 1, 1)\n",
    "\n",
    "            return weight\n",
    "\n",
    "        weight = _get_ssim_weight()#.to(self.device_type, dtype=dtype, non_blocking=True)\n",
    "        self.weight = nn.Parameter(weight, requires_grad=False)\n",
    "        \n",
    "\n",
    "    def forward(self, _im1, _im2, data_range=None):\n",
    "        \"\"\"Implementation adopted from skimage.metrics.structural_similarity\n",
    "        Default arguments set to multichannel=True, gaussian_weight=True, use_sample_covariance=False\n",
    "        \"\"\"\n",
    "        im1 = _im1.clone()\n",
    "        im2 = _im2.clone()\n",
    "#         im1 = im1.to(self.device_type, non_blocking=True)\n",
    "#         im2 = im2.to(self.device_type, non_blocking=True)\n",
    "\n",
    "        K1 = 0.01\n",
    "        K2 = 0.03\n",
    "        sigma = 1.5\n",
    "\n",
    "        truncate = 3.5\n",
    "        r = int(truncate * sigma + 0.5)  # radius as in ndimage\n",
    "        win_size = 2 * r + 1\n",
    "\n",
    "        im1 = _expand(im1)\n",
    "        im2 = _expand(im2)\n",
    "\n",
    "        nch = im1.shape[1]\n",
    "\n",
    "        if im1.shape[2] < win_size or im1.shape[3] < win_size:\n",
    "            raise ValueError(\n",
    "                \"win_size exceeds image extent.  If the input is a multichannel \"\n",
    "                \"(color) image, set multichannel=True.\")\n",
    "\n",
    "        if data_range is None:\n",
    "            data_range = 255 if im1.max() > 1 else 1\n",
    "\n",
    "        if data_range == 255:\n",
    "            im1.div_(data_range)\n",
    "            im2.div_(data_range)\n",
    "            data_range = 1\n",
    "\n",
    "        def filter_func(img):   # no padding\n",
    "            return nn.functional.conv2d(img, self.weight, groups=nch)\n",
    "            # return torch.conv2d(img, self.weight, groups=nch)\n",
    "\n",
    "        # compute (weighted) means\n",
    "        ux = filter_func(im1)\n",
    "        uy = filter_func(im2)\n",
    "\n",
    "        # compute (weighted) variances and covariances\n",
    "        uxx = filter_func(im1 * im1)\n",
    "        uyy = filter_func(im2 * im2)\n",
    "        uxy = filter_func(im1 * im2)\n",
    "        vx = (uxx - ux * ux)\n",
    "        vy = (uyy - uy * uy)\n",
    "        vxy = (uxy - ux * uy)\n",
    "\n",
    "        R = data_range\n",
    "        C1 = (K1 * R) ** 2\n",
    "        C2 = (K2 * R) ** 2\n",
    "\n",
    "        A1, A2, B1, B2 = ((2 * ux * uy + C1,\n",
    "                        2 * vxy + C2,\n",
    "                        ux ** 2 + uy ** 2 + C1,\n",
    "                        vx + vy + C2))\n",
    "        D = B1 * B2\n",
    "        S = (A1 * A2) / D\n",
    "\n",
    "        # compute (weighted) mean of ssim\n",
    "        mssim = S.mean()\n",
    "\n",
    "        return mssim    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_model.ipynb.\n",
      "Converted 02_architecture_common.ipynb.\n",
      "Converted 03_architecture_MSResNet.ipynb.\n",
      "Converted 04_dataset_common.ipynb.\n",
      "Converted 05_dataset_MSResNet.ipynb.\n",
      "Converted 06_trainer_MSResNet.ipynb.\n",
      "Converted 07_metrics.ipynb.\n",
      "Converted 99_diffaugment.ipynb.\n",
      "Converted Tutorial_without_lightning.ipynb.\n",
      "Converted model_without_lightning.ipynb.\n",
      "Converted trials.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbasecondaabb5e65e80c3430eaea8e79c153330eb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
