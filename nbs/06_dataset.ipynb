{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import albumentations as albu\n",
    "import copy\n",
    "import cv2\n",
    "from skimage.transform import pyramid_gaussian\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from typing import Tuple\n",
    "\n",
    "import torch.utils.data as data\n",
    "from defocus.blurring import hanser_defocus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseDataset(data.Dataset):\n",
    "    \"\"\"Base dataset class.\"\"\"\n",
    "    def __init__(self,\n",
    "                 input_list=None,\n",
    "                 target_list=None, \n",
    "                 forward_process=None,\n",
    "                 augment=None,\n",
    "                 corrupt=None,\n",
    "                 normalize=None,\n",
    "                 pyramid_levels=1,\n",
    "                 dim_order='NCHW', #TODO: unused argument, add support for different channel order\n",
    "                 ):\n",
    "        \"\"\"Init function.\n",
    "        \n",
    "        Args:\n",
    "            input_list: \n",
    "                a list consisting of the full paths to the input images.                 \n",
    "                if forward_process_func is not None, this should be the \n",
    "                same as the target list. the forward_process_func will \n",
    "                be applied to the inputs to simulate actual processes\n",
    "            target_list: \n",
    "                a list consisting of the full paths to the target images.\n",
    "            forward_process_func:\n",
    "                if used, the input images are transformed by this function\n",
    "                to simulate various effects. e.g. they are blurred with a\n",
    "                hanser_blur function to simulate a defocus blur\n",
    "            augment: \n",
    "                check the example yaml file. these are the augmentations \n",
    "                like flips and random crops. applied to input and target\n",
    "            corrupt: \n",
    "                check the example yaml file. these are corruptions like\n",
    "                noise, blur, jpeg compression. applied to input only\n",
    "            normalize:\n",
    "                you would think <who cares?> Seungjun says when\n",
    "                max_val=255, his models work better. so, yeah.\n",
    "                note that this does not convert to tensor so if you\n",
    "                write your own collate_fn, remember that.\n",
    "            pyramid_levels:\n",
    "                if you have a multiscale architecture, you need an image\n",
    "                pyramid. this is how many scales you have in the pyramid\n",
    "            dim_order:\n",
    "                maybe someday         \n",
    "        \"\"\"\n",
    "        super(BaseDataset, self).__init__()\n",
    "        self.input_list = input_list\n",
    "        self.target_list = target_list\n",
    "        assert len(self.input_list) == len(self.target_list)\n",
    "        # get augmentation operators\n",
    "        # if .yaml says None, just return an identity mapping\n",
    "        self.augment = get_transformation(augment) if augment is not None else lambda x, y: (x,y)\n",
    "        self.corrupt = get_transformation(corrupt) if corrupt is not None else lambda x: x\n",
    "        self.normalize = get_transformation(normalize) if normalize is not None else lambda x, y: (x,y)\n",
    "        # if .yaml says only 1 pyramid levels, i.e. the images themselves, just return an identity mapping\n",
    "        self.pyramid = get_pyramid_generator(pyramid_levels) if pyramid_levels!=1 else lambda  x, y: (x,y)\n",
    "        # forward process simulator\n",
    "        self.forward_process_func = get_forward_process(forward_process)\n",
    "        # TODO: we may want to both have distorted inputs and \n",
    "        # apply a forward_process on top. in the future. maybe.\n",
    "        if self.forward_process_func is not None:\n",
    "            self.input_list = self.target_list\n",
    "        \n",
    "        self.length = len(self.input_list)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "        \n",
    "    def __getitem__(self, idx) -> Tuple:\n",
    "        # remember that opencv has BGR order so read and convert\n",
    "        target = cv2.imread(self.target_list[idx])[:,:,::-1]        \n",
    "        # read the input image or simulate it\n",
    "        if self.forward_process_func is None:        \n",
    "            input_ = cv2.imread(self.input_list[idx])[:,:,::-1]\n",
    "        else:\n",
    "            input_, target = self.forward_process_func(target)\n",
    "        \n",
    "        input_, target = self.augment(input_, target)\n",
    "        input_ = self.corrupt(input_)\n",
    "        input_, target = self.normalize(input_, target)\n",
    "        input_, target = np.transpose(input_, (2, 0, 1)), np.transpose(target, (2, 0, 1))\n",
    "        # this is to generate an image pyramid, it is an identity function by default\n",
    "        input_, target = self.pyramid(input_, target)\n",
    "        return input_, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# TODO: tie this scale thing to the image size instead of reading \n",
    "# it from the .yaml (maybe?)\n",
    "def get_forward_process(simulator):\n",
    "    if simulator is None:\n",
    "        return None\n",
    "    kwargs = copy.deepcopy(vars(simulator))\n",
    "    forward_processes = {'hanser_defocus': hanser_defocus,\n",
    "                        }\n",
    "    function_handle = forward_processes[kwargs.pop('type')]\n",
    "    forward_process = partial(function_handle, **kwargs)\n",
    "    return forward_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# TODO: make these static functions of the BaseDataset class\n",
    "def get_transformation(augmentation):        \n",
    "    # this reads the relevant yaml part and \n",
    "    # returns an albumentation function   \n",
    "    def recursive_getattr(_augmentation):\n",
    "        augmentation = copy.deepcopy(_augmentation)\n",
    "        # I wanted to use recursion since forever\n",
    "        # I am sorry and  I won't do it again\n",
    "        if not hasattr(augmentation, 'transforms'):\n",
    "            return getattr(albu, vars(augmentation).pop('type'))(**vars(augmentation))\n",
    "        else:\n",
    "            func = getattr(albu, vars(augmentation).pop('type'))\n",
    "            transforms = vars(augmentation).pop('transforms')\n",
    "            transforms = [recursive_getattr(transform) for transform in transforms]\n",
    "            if hasattr(augmentation, 'additional_targets'):\n",
    "                vars(augmentation).pop('additional_targets')                \n",
    "                return func(**vars(augmentation), additional_targets={'target': 'image'}, transforms=transforms)\n",
    "            else:\n",
    "                return func(**vars(augmentation), transforms=transforms)\n",
    "    # aug_func is the albumentation function e.g. albu.Normalize\n",
    "    # note that this is a function object with albumentation's kwargs\n",
    "    aug_func = recursive_getattr(augmentation)\n",
    "\n",
    "    # I don't like albumentation's kwargs, so this is a wrapper:\n",
    "    def process(input_, target=None):\n",
    "        if hasattr(aug_func, 'additional_targets'):\n",
    "            returned_tuple = aug_func(image=input_, target=target)\n",
    "            return returned_tuple['image'], returned_tuple['target']\n",
    "        else:\n",
    "            return aug_func(image=input_)['image']\n",
    "\n",
    "    return process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export    \n",
    "def get_pyramid_generator(pyramid_levels):\n",
    "    def process(input_, target):\n",
    "        # the function expects CHW input, so first go back to HWC\n",
    "        input_ = input_.astype(np.float32).transpose(1,2,0)\n",
    "        target = target.astype(np.float32).transpose(1,2,0)\n",
    "        # note the order reversal. we are providing the coarsest image as input_pyramid[0]\n",
    "        # and the original resolution as the last, i.e. input_pyramid[2]\n",
    "        input_pyramid = list(pyramid_gaussian(input_, pyramid_levels-1, multichannel=True))[::-1]\n",
    "        target_pyramid = list(pyramid_gaussian(target, pyramid_levels-1, multichannel=True))[::-1]\n",
    "\n",
    "        # convert to tensors\n",
    "        # ugly, but explicit\n",
    "        input_ = []\n",
    "        target = []\n",
    "        for scaled_input, scaled_target in zip(input_pyramid, target_pyramid):\n",
    "            # ascontiguousarray is safer before tensor conversions\n",
    "            scaled_input = np.ascontiguousarray(scaled_input.transpose(2, 0, 1))\n",
    "            scaled_target = np.ascontiguousarray(scaled_target.transpose(2, 0, 1))\n",
    "            input_.append(scaled_input)\n",
    "            target.append(scaled_target)\n",
    "\n",
    "        return input_, target\n",
    "    return process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_utilities.ipynb.\n",
      "Converted 02_architecture_common.ipynb.\n",
      "Converted 03_architecture_MSResNet.ipynb.\n",
      "Converted 04_architecture_DeblurGANv2.ipynb.\n",
      "Converted 05_blurring.ipynb.\n",
      "Converted 06_dataset.ipynb.\n",
      "Converted 07_losses.ipynb.\n",
      "Converted 08_callbacks.ipynb.\n",
      "Converted 09_model.ipynb.\n",
      "Converted fuckit.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
