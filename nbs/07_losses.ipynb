{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ContentLoss(nn.Module):\n",
    "    \"\"\"Wrapper class. \n",
    "    \n",
    "    Just converts its input string to a nn function.\n",
    "    this is here mostly for consistency - perceptual and adversarial\n",
    "    losses actually do stuff.\n",
    "    \n",
    "    If you have a multiscale (i.e. image pyramids as inputs/outputs) architecture, \n",
    "    then the loss applies the criterion to input/target pairs at each scale given \n",
    "    in the multiscale arg\n",
    "    \n",
    "    The usage is like:\n",
    "    >> content_loss_instance(input, target)\n",
    "    i.e. normal forward call with a pytorch module\n",
    "    \"\"\"\n",
    "    def __init__(self, name, multiscale=None): # TODO: need a better name than multiscale, this tells nothing to the reader?!\n",
    "        super(ContentLoss, self).__init__()\n",
    "        self.multiscale = multiscale\n",
    "        if not hasattr(nn, name):\n",
    "            assert False, \"nope\"\n",
    "            fancy_content_loss_functions = {'Nope': None}            \n",
    "        else:    \n",
    "            self.criterion_func = getattr(nn, name)()\n",
    "            \n",
    "    def forward(self, fake, real):\n",
    "        if self.multiscale is None:\n",
    "            content_loss = self.criterion_func(fake, real)            \n",
    "            return content_loss\n",
    "        else:\n",
    "            content_loss = 0\n",
    "            for scale in self.multiscale:\n",
    "                content_loss += self.criterion_func(fake[scale], real[scale])\n",
    "            return content_loss\n",
    "    \n",
    "    \n",
    "class PerceptualLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    not tested. maybe I should create a self.P in lightning's __init__() \n",
    "    and pass it here?\n",
    "    \n",
    "    The usage is like:\n",
    "    >> perceptual_loss_instance(input, target)\n",
    "    i.e. normal forward call with a pytorch module\n",
    "    \"\"\"\n",
    "    def __init__(self, name, layer, criterion='L1Loss', multiscale=None, requires_grad=False):\n",
    "        super(PerceptualLoss, self).__init__()\n",
    "        self.multiscale = multiscale\n",
    "        # if yaml says None, it is None\n",
    "        if criterion is None:\n",
    "            self.criterion_func = None\n",
    "        # otherwise, do the thing\n",
    "        else:\n",
    "            self.criterion_func = getattr(nn, criterion)()\n",
    "            # original paper picks the relu2_2 from vgg16, i.e. 8th layer\n",
    "            # deblurgan picks conv3_3 from vgg19, i.e. 14th layer\n",
    "            # lpips is up to relu5_3 from vgg16 , i.e. everything \n",
    "            module = getattr(torchvision.models, name)\n",
    "            pretrained = module(pretrained=True).features\n",
    "\n",
    "            # TODO: check what lightning does for this. does it assign it to the correct cuda etc.?\n",
    "            # if not I may have to create the network separately in the LightningModule __init__()\n",
    "            self.network = nn.Sequential()\n",
    "            # it is layer+1 because we add including the \"layer\" in the yaml\n",
    "            for i in range(layer+1):\n",
    "                self.network.add_module(str(pretrained[i]), pretrained[i])            \n",
    "            \n",
    "    def forward(self, fake, real):\n",
    "        # TODO: deblurgan does some weird stuff here, check it:\n",
    "        \"\"\"\n",
    "        self.transform = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        fakeIm = (fakeIm + 1) / 2.0\n",
    "        realIm = (realIm + 1) / 2.0\n",
    "        fakeIm[0, :, :, :] = self.transform(fakeIm[0, :, :, :])\n",
    "        realIm[0, :, :, :] = self.transform(realIm[0, :, :, :]) \n",
    "        \n",
    "        # and then in the forward pass further weird stuff. they do pixelwise MSE, scale it with 0.5,\n",
    "        # do perceptual, scale it by 0.006 and add them, but they have pixelwise separately... wtf?\n",
    "        \"\"\"\n",
    "        if self.criterion_func is None:\n",
    "            return 0\n",
    "        # don't accumalate gradient for real, doesn't make sense\n",
    "        real_features = self.network(real).detach()\n",
    "        fake_features = self.network(fake)\n",
    "        content_loss = self.criterion_func(fake_features, real_features)\n",
    "        return content_loss\n",
    "    \n",
    "\n",
    "class AdversarialLoss():\n",
    "    \"\"\"\n",
    "    wrapper class. it just calls the actual GAN loss e.g. WGAN_with_GP\n",
    "    For this, there is no forward call, you need to specifically call a\n",
    "    calculate_<some_loss> function\n",
    "    \n",
    "    If you have a multiscale (i.e. image pyramids as inputs/outputs) architecture, \n",
    "    then the loss applies the calculate_<some_loss> to input/target pairs at each \n",
    "    scale given in the multiscale arg    \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, name, multiscale=None):\n",
    "        self.multiscale = multiscale\n",
    "        #https://docs.python.org/3/faq/programming.html#how-do-i-use-strings-to-call-functions-methods\n",
    "        adversarial_modes = {'WGAN_with_GP': WGAN_with_GP,\n",
    "                             'RaLSGAN' : RaLSGAN,\n",
    "                            }\n",
    "        self.adversarial = adversarial_modes[name]()\n",
    "    \n",
    "    def calculate_D_loss(self, D, fake, real):\n",
    "        if self.multiscale is None:\n",
    "            return self.adversarial.calculate_D_loss(D, fake, real)\n",
    "        else:            \n",
    "            D_loss = 0\n",
    "            for scale in self.multiscale:\n",
    "                D_loss += self.adversarial.calculate_D_loss(D, fake[scale], real[scale])\n",
    "            return D_loss\n",
    "    \n",
    "    def calculate_G_loss(self, D, fake, real):\n",
    "        if self.multiscale is None:\n",
    "            return self.adversarial.calculate_G_loss(D, fake, real)\n",
    "        else:            \n",
    "            G_loss = 0\n",
    "            for scale in self.multiscale:\n",
    "                G_loss += self.adversarial.calculate_G_loss(D, fake[scale], real[scale])\n",
    "            return G_loss\n",
    "    \n",
    "\n",
    "class WGAN_with_GP(nn.Module):\n",
    "    '''\n",
    "    WGAN with gradient penalty. Get an instance of it, then call\n",
    "    calculate_G_loss() or calculate_D_loss(). \n",
    "    \n",
    "    Note that you need to pass these functions the critic/discriminator network.\n",
    "    Why did I do it like this? Because this way we can go crazy with our loss_func,\n",
    "    but the training code stays clean. also diff-aug before the D will be cleaner.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(WGAN_with_GP, self).__init__()\n",
    "        # lambda=10 is the default from the original paper\n",
    "        # they say it works for cifar10 to ImageNet, so ok I guess\n",
    "        # Anyway, I took this from deblurgan repo but I think they took it from:\n",
    "        # https://github.com/caogang/wgan-gp/blob/master/gan_cifar10.py\n",
    "        self.LAMBDA = 10\n",
    "    \n",
    "    def calculate_G_loss(self, D, fake, real):\n",
    "        # TODO: check:\n",
    "        # what is this explicitly calling the forward thing?\n",
    "        # this is not good practice, why did I do this?\n",
    "#         pred_fake = D.forward(fake) \n",
    "        pred_fake = D(fake)\n",
    "        return -pred_fake.mean()\n",
    "        \n",
    "    def calculate_D_loss(self, D, fake, real):\n",
    "        pred_fake = D(fake.detach())\n",
    "        pred_fake = pred_fake.mean()\n",
    "\n",
    "        pred_real = D(real)\n",
    "        pred_real = pred_real.mean()\n",
    "        \n",
    "        D_loss = pred_fake - pred_real\n",
    "        gradient_penalty = self.calc_gradient_penalty(D, fake.data, real.data)\n",
    "        \n",
    "        return D_loss + gradient_penalty\n",
    "    \n",
    "    def calc_gradient_penalty(self, D, fake, real):\n",
    "        # careful here with all the cuda devices! note that lightning don't\n",
    "        # like explicit device assignments\n",
    "        alpha = torch.rand(1, 1)\n",
    "        alpha = alpha.expand(real.size())\n",
    "        alpha = alpha.cuda(real.device.index)\n",
    "\n",
    "        interpolates = alpha * real + ((1 - alpha) * fake)\n",
    "\n",
    "        interpolates = interpolates.cuda(real.device.index)\n",
    "        interpolates = Variable(interpolates, requires_grad=True)\n",
    "\n",
    "        disc_interpolates = D(interpolates)\n",
    "\n",
    "        gradients = autograd.grad(outputs=disc_interpolates, \n",
    "                                  inputs=interpolates,\n",
    "                                  grad_outputs=torch.ones(disc_interpolates.size()).cuda(real.device.index),\n",
    "                                  create_graph=True, \n",
    "                                  retain_graph=True, \n",
    "                                  only_inputs=True)[0]\n",
    "\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * self.LAMBDA\n",
    "        return gradient_penalty\n",
    "    \n",
    "class RaLSGAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RaLSGAN, self).__init__()\n",
    "\n",
    "    def calculate_G_loss(self, D, fake, real):        \n",
    "        pred_fake = D(fake)\n",
    "        pred_real = D(real)\n",
    "        G_loss = (torch.mean((pred_real - torch.mean(pred_fake) + 1) ** 2) +\n",
    "                  torch.mean((pred_fake - torch.mean(pred_real) - 1) ** 2)) / 2\n",
    "        return G_loss\n",
    "\n",
    "    def calculate_D_loss(self, D, fake, real):\n",
    "        pred_fake = D(fake.detach())\n",
    "        pred_real = D(real)\n",
    "\n",
    "        D_loss = (torch.mean((pred_real - torch.mean(pred_fake) - 1) ** 2) +\n",
    "                  torch.mean((pred_fake - torch.mean(pred_real) + 1) ** 2)) / 2\n",
    "        return D_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_utilities.ipynb.\n",
      "Converted 02_architecture_common.ipynb.\n",
      "Converted 03_architecture_MSResNet.ipynb.\n",
      "Converted 04_architecture_DeblurGANv2.ipynb.\n",
      "Converted 05_blurring.ipynb.\n",
      "Converted 06_dataset.ipynb.\n",
      "Converted 07_losses.ipynb.\n",
      "Converted 08_callbacks.ipynb.\n",
      "Converted fuckit.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
