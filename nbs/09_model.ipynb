{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import importlib\n",
    "import copy\n",
    "from functools import partial\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "from adamp import AdamP\n",
    "\n",
    "from defocus.utilities import get_metrics, get_GOPRO_lists\n",
    "from defocus.losses import ContentLoss, AdversarialLoss, PerceptualLoss\n",
    "from defocus.dataset import BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams\n",
    "        G_architecture = self.hparams.model.generator.architecture\n",
    "        D_architecture = self.hparams.model.discriminator.architecture\n",
    "        # TODO: maybe I shouldn't use importlib but do something else?\n",
    "        self.G = importlib.import_module('defocus.architecture.' + G_architecture).Generator() \n",
    "        self.D = importlib.import_module('defocus.architecture.' + D_architecture).Discriminator() \n",
    "        # TODO: for consistency, there should be a self.P and all that stuff maybe?\n",
    "        \n",
    "#         self.content_loss = ContentLoss(name=self.hparams.model.loss.content_loss.name,\n",
    "#                                         multiscale=self.hparams.model.loss.content_loss.multiscale,\n",
    "#                                        )\n",
    "#         self.adversarial_loss = AdversarialLoss(name=self.hparams.model.loss.adversarial_loss.name,\n",
    "#                                                 multiscale=self.hparams.model.loss.adversarial_loss.multiscale,\n",
    "#                                                )\n",
    "#         self.perceptual_loss = PerceptualLoss(name=self.hparams.model.loss.perceptual_loss.name,\n",
    "#                                               layer=self.hparams.model.loss.perceptual_loss.layer,\n",
    "#                                               criterion=self.hparams.model.loss.perceptual_loss.criterion,\n",
    "#                                               multiscale=self.hparams.model.loss.adversarial_loss.multiscale,\n",
    "#                                              )\n",
    "#         self.adversarial_weight = self.hparams.model.loss.adversarial_loss.weight\n",
    "#         self.content_weight = self.hparams.model.loss.content_loss.weight\n",
    "#         # TODO: perceptual weight is untested\n",
    "#         self.perceptual_weight = self.hparams.model.loss.perceptual_loss.weight\n",
    "        self.content_loss = ContentLoss(**vars(self.hparams.model.loss.content_loss))\n",
    "        self.adversarial_loss = AdversarialLoss(**vars(self.hparams.model.loss.adversarial_loss))\n",
    "        self.perceptual_loss = PerceptualLoss(**vars(self.hparams.model.loss.perceptual_loss))\n",
    "        \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx=None):\n",
    "        input_, target = batch\n",
    "        output = self.G(input_)\n",
    "        \n",
    "        if optimizer_idx == 0:\n",
    "            # TODO: remove commented lines after testing\n",
    "#             loss_d = self.adversarial_weight * self.adversarial_loss.calculate_D_loss(self.D, output, target)\n",
    "            loss_d = self.adversarial_loss.calculate_D_loss(self.D, output, target)\n",
    "            # lightning's logging practices are ALWAYS changing, this was for 1.0.8    \n",
    "            self.log('train_loss_d', loss_d)            \n",
    "            return loss_d\n",
    "        \n",
    "        elif optimizer_idx == 1:\n",
    "            # TODO: remove commented lines after testing\n",
    "#             loss_content = self.content_weight * self.content_loss(output, target)\n",
    "            loss_content = self.content_loss(output, target)\n",
    "            loss_perceptual = self.perceptual_loss(output, target)\n",
    "            # TODO: another level of commenting, remove and remove\n",
    "#             # TODO: better one is the commented lines but for consistency, \n",
    "#             # I keep using the latter code. Once I am sure, uncomment these and delete the latter\n",
    "#             # loss_adv = self.adversarial_weight * self.adversarial_loss.calculate_G_loss(self.D, output, target)\n",
    "#             # loss_g = loss_content + loss_adv\n",
    "#             loss_adv = self.adversarial_loss.calculate_G_loss(self.D, output, target)\n",
    "#             loss_g = loss_content + self.adversarial_weight * loss_adv\n",
    "            loss_adv = self.adversarial_loss.calculate_G_loss(self.D, output, target)\n",
    "            loss_g = loss_content + loss_adv + loss_perceptual\n",
    "            \n",
    "            # lightning's logging practices are ALWAYS changing, this was for 1.0.8    \n",
    "            self.log('train_loss_g', loss_g)\n",
    "            self.log('train_loss_content', loss_content)\n",
    "            self.log('train_loss_g_adv', loss_adv)\n",
    "            self.log('train_loss_perceptual', loss_perceptual)\n",
    "            return loss_g\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # I had to do this. hooks didn't work. \n",
    "        # modifying on_validation_model_eval didn't work with ddp... \n",
    "        # this is as of lightning 1.0.8\n",
    "        self.train()\n",
    "        assert self.G.training, \"Don't use the exp-avg batch norm stats, this is a GAN, it won't work.\"\n",
    "        input_, target = batch\n",
    "        output = self.G(input_)\n",
    "        \n",
    "        psnr, ssim = get_metrics(input_, output, target)    \n",
    "        # lightning's logging best practices are ALWAYS changing, this was for 1.0.8 \n",
    "        self.log('val_PSNR', torch.tensor(psnr).type_as(output), sync_dist=True)\n",
    "        self.log('val_SSIM', torch.tensor(ssim).type_as(output), sync_dist=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # and finally setup Adam\n",
    "        opt_G_func = get_optimizer(self.hparams.model.generator.optimizer)\n",
    "        opt_D_func = get_optimizer(self.hparams.model.discriminator.optimizer)\n",
    "        optimizer_G = opt_G_func(self.G.parameters())\n",
    "        optimizer_D = opt_D_func(self.D.parameters())\n",
    "        \n",
    "        # and now actually setup the scheduler\n",
    "        scheduler_G_func = get_scheduler(self.hparams.model.generator.scheduler)\n",
    "        scheduler_D_func = get_scheduler(self.hparams.model.discriminator.scheduler)\n",
    "        scheduler_G = scheduler_G_func(optimizer_G)\n",
    "        scheduler_D = scheduler_D_func(optimizer_D) \n",
    "        \n",
    "        return [optimizer_D, optimizer_G], [scheduler_D, scheduler_G]\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        return self.G(input_)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        # TODO: get_GOPRO_lists is not modular, change that thing and handle\n",
    "        # the datasets, i.e. GOPRO or REDS or DIV2K or whatevet inside the get_thing()\n",
    "        input_list, target_list = get_GOPRO_lists(root_folder=self.hparams.input.datapath.root_folder,\n",
    "                                                  image_pair_list=self.hparams.input.datapath.image_pair_list\n",
    "                                                 )\n",
    "        train_set=BaseDataset(input_list=input_list,\n",
    "                              target_list=target_list,\n",
    "                              forward_process=self.hparams.input.training_forward_process_simulator,\n",
    "                              augment=self.hparams.input.training_augmentations,\n",
    "                              corrupt=self.hparams.input.training_corruptions,\n",
    "                              normalize=self.hparams.input.training_normalization,\n",
    "                              pyramid_levels=self.hparams.input.pyramid_levels,\n",
    "                             )\n",
    "        train_loader = DataLoader(train_set, \n",
    "                                  batch_size=self.hparams.training.batch_size, \n",
    "                                  num_workers=self.hparams.training.num_workers, \n",
    "                                  drop_last=True, \n",
    "                                  shuffle=True,\n",
    "                                 )\n",
    "        return train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        # TODO: the get_DATASET_list() functions should be an input argument\n",
    "        input_list, target_list = get_GOPRO_lists(root_folder=self.hparams.input.datapath.root_folder,\n",
    "                                                  image_pair_list=self.hparams.input.datapath.val_image_pair_list\n",
    "                                                 )\n",
    "        val_set=BaseDataset(input_list=input_list,\n",
    "                            target_list=target_list,\n",
    "                            forward_process=self.hparams.input.validation_forward_process_simulator,\n",
    "                            augment=self.hparams.input.validation_augmentations,\n",
    "                            corrupt=self.hparams.input.validation_corruptions,\n",
    "                            normalize=self.hparams.input.validation_normalization,\n",
    "                            pyramid_levels=self.hparams.input.pyramid_levels,\n",
    "                           )\n",
    "        val_loader = DataLoader(val_set, \n",
    "                                batch_size=self.hparams.training.batch_size, \n",
    "                                num_workers=self.hparams.training.num_workers, \n",
    "                                drop_last=True,\n",
    "                                shuffle=False,\n",
    "                               )\n",
    "        return val_loader\n",
    "    \n",
    "#     # lightning changes function arguments a lot as well, this is for version 1.0.8\n",
    "#     def backward(self, loss, optimizer, optimizer_idx):\n",
    "#         # I really don't get why I retained the graph after the D update?\n",
    "#         # we feed a detached fake to D, so no gradients for G. which should mean that\n",
    "#         # the backward should only destroy D's graph. \n",
    "#         # TODO: check this. go back to default backward and see what happens\n",
    "#         # in vanilla pytorch: it works. but still, let's pay extra attention to zero_grads\n",
    "#         # so as not to leak gradients anywhere\n",
    "#         if optimizer_idx == 0:\n",
    "#             loss.backward(retain_graph=True)\n",
    "#         elif optimizer_idx == 1:\n",
    "#             loss.backward()\n",
    "\n",
    "# this also doesn't work as of lightning 1.0.8\n",
    "#     def on_validation_model_eval(self):\n",
    "#         # I don't like this way of doing things, feels non-lightning\n",
    "#         # I made a comment here:\n",
    "#         # https://github.com/PyTorchLightning/pytorch-lightning/issues/2551#issuecomment-742601083\n",
    "#         self.train()\n",
    "        \n",
    "    \n",
    "    def on_test_model_eval(self):\n",
    "        # same thing as on_validation_model_eval\n",
    "        self.train()\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        assert self.G.training, \"Don't use the exp-avg batch norm stats, this is a GAN, it won't work.\"\n",
    "        input_, target = batch\n",
    "        output = self.G(input_)\n",
    "        \n",
    "        psnr, ssim = get_metrics(input_, output, target)    \n",
    "        # lightning's logging best practices are ALWAYS changing, this was for 1.0.8    \n",
    "        self.log('test_PSNR', torch.tensor(psnr))\n",
    "        self.log('test_SSIM', torch.tensor(ssim))\n",
    "        return {'test_PSNR': torch.tensor(psnr), 'test_SSIM': torch.tensor(ssim)}\n",
    "        \n",
    "    def test_epoch_end(self, test_step_outputs):\n",
    "        ssims = 0\n",
    "        psnrs = 0\n",
    "        for result in test_step_outputs:\n",
    "            ssims += result['test_SSIM']\n",
    "            psnrs += result['test_PSNR']\n",
    "        length = len(test_step_outputs)\n",
    "        print('test_SSIM is {} and test_PSNR is {}'.format(ssims/length, psnrs/length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# this func is usually just to get Adam using the config.yaml parameters\n",
    "def get_optimizer(args):\n",
    "    kwargs = copy.deepcopy(vars(args))\n",
    "    other_opts = {'AdamP': AdamP,\n",
    "                 }\n",
    "    name = kwargs.pop('name')\n",
    "    if hasattr(optim, name):\n",
    "        return partial(getattr(optim, name), **kwargs)\n",
    "    else:\n",
    "        return partial(other_opts[name], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# same thing, but to create a scheduler this time\n",
    "def get_scheduler(args): \n",
    "    kwargs = copy.deepcopy(vars(args))\n",
    "    other_schedulers = {'LinearDecay': LinearDecay,\n",
    "                       }\n",
    "    name = kwargs.pop('name')\n",
    "    if hasattr(lr_scheduler, name):\n",
    "        return partial(getattr(lr_scheduler, name), **kwargs)\n",
    "    else:\n",
    "        return partial(other_schedulers[name], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "# TODO: put this into some .py file\n",
    "# but actually, don't use it, I don't see a reason for a new scheduler\n",
    "# this is from DeblurGANv2 by the way\n",
    "class LinearDecay(lr_scheduler._LRScheduler):\n",
    "    \"\"\"This class implements LinearDecay\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, num_epochs, start_epoch=0, min_lr=0, last_epoch=-1):\n",
    "        \"\"\"implements LinearDecay\n",
    "        Parameters:\n",
    "        ----------\n",
    "        \"\"\"\n",
    "        self.num_epochs = num_epochs - start_epoch # I changed this # num_epochs\n",
    "        self.start_epoch = start_epoch\n",
    "        self.min_lr = min_lr\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch < self.start_epoch:\n",
    "            return self.base_lrs\n",
    "        return [base_lr - ((base_lr - self.min_lr) / self.num_epochs) * (self.last_epoch - self.start_epoch) for\n",
    "                base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_utilities.ipynb.\n",
      "Converted 02_architecture_common.ipynb.\n",
      "Converted 03_architecture_MSResNet.ipynb.\n",
      "Converted 04_architecture_DeblurGANv2.ipynb.\n",
      "Converted 05_blurring.ipynb.\n",
      "Converted 06_dataset.ipynb.\n",
      "Converted 07_losses.ipynb.\n",
      "Converted 08_callbacks.ipynb.\n",
      "Converted 09_model.ipynb.\n",
      "Converted fuckit.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
