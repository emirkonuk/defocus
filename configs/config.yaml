training:
  seed: 42 # leave empty 
  batch_size: 8
  num_gpu: 2
  num_workers: 8
  fp16: true
  max_epochs: &MAX_EPOCHS 250
  metric:
    - SSIM
    - PSNR
  upload_to_wb:

input:
  datapath:
    root_folder: /storage/ekonuk/projects/all_datasets/GOPRO/train/
    image_pair_list: /storage/ekonuk/projects/all_datasets/GOPRO/train/train_image_pair_list.txt
    val_image_pair_list: /storage/ekonuk/projects/all_datasets/GOPRO/train/val_image_pair_list.txt
  dimension_order: NCHW # TODO: this is unused for now
  size: &SIZE 256
  # how many downsampled image pyramid scales are used
  # IMPORTANT: this must match what the architecture expects as input
  # it is here mostly for 
  pyramid_levels: 1 
  # IMPORTANT: if you provide a simulator, your input_file_list will be overridden by the target_file_list
  training_forward_process_simulator: &FORWARD_PROCESS # remove type etc. if your dataset has an actual/real distortion 
    type: hanser_defocus 
    # put the kwargs of your forward_process_func here
    scale: 1.0
  validation_forward_process_simulator: *FORWARD_PROCESS
  training_normalization: &TRAINING_NORMALIZATION
    type: Compose
    additional_targets: true
    p: 1.0
    transforms:
      - type: Normalize
        max_pixel_value: 255.0 #note that this is the input's max, not what you want
        mean:
          - 0.5
          - 0.5
          - 0.5
        std:
          - 0.5
          - 0.5
          - 0.5
  validation_normalization: *TRAINING_NORMALIZATION
   # these are from albumentations, use their API here
  training_augmentations:
    type: Compose
    additional_targets: true
    p: 1.0
    transforms:
      - type: OneOf
        p: 1.0
        transforms:
        - type: HorizontalFlip
        - type: ShiftScaleRotate
        - type: Transpose
        - type: OpticalDistortion
        - type: ElasticTransform
      - type: RandomCrop
        height: *SIZE
        width: *SIZE
        always_apply: true
      - type: PadIfNeeded
        min_height: *SIZE
        min_width: *SIZE 
  validation_augmentations:
    type: Compose
    additional_targets: true
    p: 1.0
    transforms:
      - type: OneOf
        p: 1.0
        transforms:
        - type: HorizontalFlip
        - type: ShiftScaleRotate
        - type: Transpose
        - type: OpticalDistortion
        - type: ElasticTransform
      - type: CenterCrop
        height: *SIZE
        width: *SIZE
        always_apply: true
      - type: PadIfNeeded
        min_height: *SIZE
        min_width: *SIZE  
  training_corruptions: &TRAINING_CORRUPTIONS
    type: OneOf # can't have additional targets
    p: 0.5
    transforms: &CORRUPT
#     - type: Cutout # this is not classification what are we teaching here, how to deal with black boxes?
#       num_holes: 3
#       max_h_size: 25
#       max_w_size: 25
#     - type: JpegCompression # I am VERY suspicios about this corruption. shouldn't be used
#       quality_lower: 70
#       quality_upper: 90
#     - type: MotionBlur
#     - type: MedianBlur
    - type: RandomGamma
    - type: RGBShift
    - type: HueSaturationValue
#     - type: IAASharpen   # I am VERY suspicios about this corruption. shouldn't be used
  validation_corruptions: *TRAINING_CORRUPTIONS


model:
  callbacks: DeblurGANv2Callbacks
  generator:
    architecture: &ARCHITECTURE DeblurGANv2 # MSResNet #
    optimizer: &OPTIMIZER
      name: Adam
      lr: 1e-4
    scheduler: &SCHEDULER
      name: LinearDecay # DeblurGANv2 scheduler is LinearDecay
      num_epochs: *MAX_EPOCHS
      start_epoch: 50
      min_lr: 0.0000001
  discriminator:
    architecture: *ARCHITECTURE
    optimizer: *OPTIMIZER
    scheduler: *SCHEDULER
    differentiable_augmentations: #TODO, kornia or other differentiable augs here
  loss:
    adversarial_loss: 
        name: RaLSGAN
        weight: 0.001
        # if using a multiscale architecture, provide a list for which image scales
        # the loss is applied (0 is the smallest resolution)
        multiscale: #[2]
    content_loss:
        name: L1Loss
        weight: 1.0
        # if using a multiscale architecture, provide a list for which image scales
        # the loss is applied (0 is the smallest resolution)
        multiscale: #[0,1,2]
    perceptual_loss: 
    # original paper picks the relu2_2 from vgg16, i.e. 8th layer
    # deblurgan picks conv3_3 from vgg19, i.e. 14th layer
    # lpips is up to relu5_3 from vgg16 , i.e. everything
        name: #vgg19
        layer: #14
        criterion: #L1Loss
        weight: #1.0
        # if using a multiscale architecture, provide a list for which image scales
        # the loss is applied (0 is the smallest resolution)
        multiscale: #[2]
    stop_loss:
    flood_loss: 0